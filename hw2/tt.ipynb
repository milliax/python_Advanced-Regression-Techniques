{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./train.csv\"\n",
    "predict_data_path = \"./test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "predict_df = pd.read_csv(predict_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tell apart continuous data and dsicrete data\n",
    "continuous_columns = [\"Id\", \"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\", \"BsmtUnfSF\" , \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"LowQualFinSF\", \"GrLivArea\", \"BsmtFullBath\", \"BsmtHalfBath\", \"FullBath\", \"HalfBath\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\", \"GarageCars\", \"GarageArea\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\", \"ScreenPorch\", \"PoolArea\", \"MiscVal\", \"YearBuilt\", \"YearRemodAdd\", \"GarageYrBlt\", \"SalePrice\"]\n",
    "discrete_columns = []\n",
    "Id_for_ans = predict_df[\"Id\"].values.tolist()\n",
    "for i in train_df.columns.values.tolist():\n",
    "    if (i in continuous_columns)==False:\n",
    "        discrete_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out the columns that consist of more than half NANs\n",
    "number_of_data = train_df.shape[0]\n",
    "number_of_nan = train_df.isna().sum().to_dict()\n",
    "drop_columns = []\n",
    "for i in number_of_nan:\n",
    "    if number_of_nan[i]>=number_of_data/2:\n",
    "        drop_columns.append(i)\n",
    "\n",
    "for i in drop_columns:\n",
    "    if i in continuous_columns:\n",
    "        continuous_columns.remove(i)\n",
    "    else:\n",
    "        discrete_columns.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the final columns that I want to use\n",
    "select_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算連續型資料的相關係數\n",
    "continuous_df = train_df[continuous_columns]\n",
    "corr = continuous_df.corr().values.tolist()\n",
    "for i, j in zip(continuous_df.columns.values.tolist(), corr[-1]):\n",
    "    if j>=0.6 and i!=\"SalePrice\":\n",
    "        select_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#移除離群值\n",
    "train_df = train_df[train_df[\"TotalBsmtSF\"]<=2900]\n",
    "train_df = train_df[train_df[\"1stFlrSF\"]<=2500]\n",
    "train_df = train_df[train_df[\"GrLivArea\"]<=3600]\n",
    "train_df = train_df[train_df[\"GarageArea\"]<=1200]\n",
    "select_columns.remove(\"GarageCars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算離散型資料 \n",
    "discrete_df = train_df[discrete_columns]\n",
    "for i in discrete_columns:\n",
    "    one_hot = pd.get_dummies(discrete_df[i])\n",
    "    rename_dic = {}\n",
    "    for j in one_hot.columns.values.tolist():\n",
    "        rename_dic[j] = str(i)+\"_\"+str(j)\n",
    "    one_hot = one_hot.rename(columns=rename_dic)\n",
    "    discrete_df = discrete_df.drop(i, axis=1)\n",
    "    discrete_df = discrete_df.join(one_hot)\n",
    "\n",
    "discrete_df.replace(True, 1, inplace=True)\n",
    "discrete_df.replace(False, 0, inplace=True)\n",
    "\n",
    "discrete_df = discrete_df.join(train_df[\"SalePrice\"])\n",
    "\n",
    "corr = discrete_df.corr().values.tolist()\n",
    "for i, j in zip(discrete_df.columns.values.tolist(), corr[-1]):\n",
    "    if j>=0.05 and i!=\"SalePrice\":\n",
    "        select_columns.append(i)\n",
    "        #print(i+\" : \"+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in discrete_columns:\n",
    "    one_hot = pd.get_dummies(train_df[i])\n",
    "    rename_dic = {}\n",
    "    for j in one_hot.columns.values.tolist():\n",
    "        rename_dic[j] = str(i)+\"_\"+str(j)\n",
    "    one_hot = one_hot.rename(columns=rename_dic)\n",
    "    train_df = train_df.drop(i, axis=1)\n",
    "    train_df = train_df.join(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ans(predict_target):\n",
    "    #write the result into ans.csv\n",
    "    ansDict = {\n",
    "        \"Id\" : Id_for_ans,\n",
    "        \"SalePrice\" : predict_target\n",
    "    }\n",
    "    ansDf = pd.DataFrame(ansDict)\n",
    "    ansDf.to_csv(\"ans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(train_df, select_columns):\n",
    "    #split 20% of the train data to test data\n",
    "    train_label = train_df[select_columns].values\n",
    "    train_target = train_df[\"SalePrice\"].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_label, train_target, test_size=0.2)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_module(train_df, select_columns):\n",
    "    x_train, x_test, y_train, y_test = data_split(train_df, select_columns)\n",
    "\n",
    "    #build a gradient descent module and test whether the columns we choose is good enough\n",
    "    std = StandardScaler()\n",
    "\n",
    "    x_train = std.fit_transform(x_train)\n",
    "    x_test = std.fit_transform(x_test)\n",
    "\n",
    "    sgd = SGDRegressor()\n",
    "\n",
    "    sgd.fit(x_train, y_train)\n",
    "    sgd_pre = sgd.predict(x_test)\n",
    "\n",
    "    sgd_mean_square = mean_squared_error(y_test, sgd_pre)\n",
    "\n",
    "    return sgd_mean_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_module(train_df, select_columns):\n",
    "\n",
    "    #x_train, x_test, y_train, y_test = data_split(train_df, select_columns)\n",
    "\n",
    "    x_train = train_df[select_columns].values\n",
    "    y_train = train_df[\"SalePrice\"].values\n",
    "\n",
    "    #build a gradient descent module and test whether the columns we choose is good enough\n",
    "    std = StandardScaler()\n",
    "\n",
    "    x_train = std.fit_transform(x_train)\n",
    "    #x_test = std.fit_transform(x_test)\n",
    "\n",
    "    sgd = SGDRegressor()\n",
    "\n",
    "    sgd.fit(x_train, y_train)\n",
    "    #sgd_pre = sgd.predict(x_test)\n",
    "\n",
    "    #sgd_mean_square = mean_squared_error(y_test, sgd_pre)\n",
    "\n",
    "\n",
    "    return std, sgd\n",
    "\n",
    "    #0.4 : 612480768.8626099\n",
    "    #0.2 : 530552347.7190159\n",
    "    #0.1 : 454339807.24334556\n",
    "    #0.05 : 433638264.14439946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(std, sgd, predict_df):\n",
    "    predict_df_columns = predict_df.columns.values.tolist()\n",
    "    #assume that the module is good enough, predict the data in test.csv with the module\n",
    "    for i in discrete_columns:\n",
    "        one_hot = pd.get_dummies(predict_df[i])\n",
    "        rename_dic = {}\n",
    "        for j in one_hot.columns.values.tolist():\n",
    "            rename_dic[j] = str(i)+\"_\"+str(j)\n",
    "        one_hot = one_hot.rename(columns=rename_dic)\n",
    "        predict_df = predict_df.drop(i, axis=1)\n",
    "        predict_df = predict_df.join(one_hot)\n",
    "\n",
    "    for i in select_columns:\n",
    "        if (i in predict_df_columns)==False:\n",
    "            predict_df[i] = [0 for j in range(predict_df.shape[0])]\n",
    "    \n",
    "    predict_df = predict_df[select_columns]\n",
    "    predict_df.replace(True, 1, inplace=True)\n",
    "    predict_df.replace(False, 0, inplace=True)\n",
    "\n",
    "    for i in predict_df.columns.values.tolist():\n",
    "        predict_df[i] = predict_df[i].fillna(predict_df[i].mean())\n",
    "\n",
    "\n",
    "    predict_label = predict_df.values\n",
    "    predict_label = std.fit_transform(predict_label)\n",
    "\n",
    "    predict_target = sgd.predict(predict_label)\n",
    "    return predict_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predicting :   0%|                                                         | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predicting : 100%|██████████████████████████████████████████████| 1000/1000 [00:15<00:00, 63.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max : 1253335556.3360887\n",
      "min : 400162090.9629915\n",
      "avg : 615815288.759271\n",
      "med : 601567108.2629598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_sqd_mean_square = []\n",
    "for i in tqdm(range(1000), desc=\"predicting \", ncols=100):\n",
    "    sgd_mean_square = build_test_module(train_df, select_columns)\n",
    "    all_sqd_mean_square.append(sgd_mean_square)\n",
    "\n",
    "print(\"max : {0}\".format(max(all_sqd_mean_square))) \n",
    "print(\"min : {0}\".format(min(all_sqd_mean_square)))\n",
    "print(\"avg : {0}\".format(np.mean(all_sqd_mean_square)))\n",
    "print(\"med : {0}\".format(np.percentile(all_sqd_mean_square, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "std, sgd = build_module(train_df, select_columns)\n",
    "predict_target = predict(std, sgd, predict_df)\n",
    "write_ans(predict_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
